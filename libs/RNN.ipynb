{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eaTI-Dn1RTK6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaTI-Dn1RTK6",
        "outputId": "a461354a-74ed-414e-e344-14d8da7091cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk==3.6.1 in /usr/local/lib/python3.7/dist-packages (3.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.1) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.1) (4.59.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.1) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.1) (2019.12.20)\n",
            "Requirement already satisfied: numpy==1.18.5 in /usr/local/lib/python3.7/dist-packages (1.18.5)\n",
            "Requirement already satisfied: pandas==1.3.0 in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.0) (1.15.0)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (3.10.0.2)\n",
            "Requirement already satisfied: tqdm==4.59.0 in /usr/local/lib/python3.7/dist-packages (4.59.0)\n",
            "Requirement already satisfied: scikit_learn==1.0.2 in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.2) (1.18.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.2) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.2) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "# Import the required packages\n",
        "!pip install nltk==3.6.1\n",
        "!pip install numpy==1.18.5\n",
        "!pip install pandas==1.3.0\n",
        "!pip install torch==1.9.0\n",
        "!pip install tqdm==4.59.0\n",
        "!pip install scikit_learn==1.0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6ccf15cd",
      "metadata": {
        "id": "6ccf15cd"
      },
      "outputs": [],
      "source": [
        "# Import the required libraries\n",
        "import re\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5547d608",
      "metadata": {
        "id": "5547d608"
      },
      "outputs": [],
      "source": [
        "# Define configuration file paths\n",
        "lr = 0.0001  # Learning rate for training\n",
        "input_size = 50  # Input size for the neural network\n",
        "num_epochs = 50  # Number of training epochs\n",
        "hidden_size = 50  # Size of the hidden layer in the neural network\n",
        "label_col = \"Product\"  # Name of the label column in the dataset\n",
        "tokens_path = \"Output/tokens.pkl\"  # Path to save token data\n",
        "labels_path = \"Output/labels.pkl\"  # Path to save label data\n",
        "data_path = \"Input/complaints.csv\"  # Path to the input data CSV file\n",
        "rnn_model_path = \"Output/model_rnn.pth\"  # Path to save the RNN model\n",
        "lstm_model_path = \"Output/model_lstm.pth\"  # Path to save the LSTM model\n",
        "vocabulary_path = \"Output/vocabulary.pkl\"  # Path to save the vocabulary\n",
        "embeddings_path = \"Output/embeddings.pkl\"  # Path to save word embeddings\n",
        "glove_vector_path = \"Input/glove.6B.50d.txt\"  # Path to the GloVe word vectors file\n",
        "text_col_name = \"Consumer complaint narrative\"  # Name of the text column in the dataset\n",
        "label_encoder_path = \"Output/label_encoder.pkl\"  # Path to save the label encoder\n",
        "\n",
        "# Mapping of product names to shorter labels\n",
        "product_map = {\n",
        "    'Vehicle loan or lease': 'vehicle_loan',\n",
        "    'Credit reporting, credit repair services, or other personal consumer reports': 'credit_report',\n",
        "    'Credit card or prepaid card': 'card',\n",
        "    'Money transfer, virtual currency, or money service': 'money_transfer',\n",
        "    'virtual currency': 'money_transfer',\n",
        "    'Mortgage': 'mortgage',\n",
        "    'Payday loan, title loan, or personal loan': 'loan',\n",
        "    'Debt collection': 'debt_collection',\n",
        "    'Checking or savings account': 'savings_account',\n",
        "    'Credit card': 'card',\n",
        "    'Bank account or service': 'savings_account',\n",
        "    'Credit reporting': 'credit_report',\n",
        "    'Prepaid card': 'card',\n",
        "    'Payday loan': 'loan',\n",
        "    'Other financial service': 'others',\n",
        "    'Virtual currency': 'money_transfer',\n",
        "    'Student loan': 'loan',\n",
        "    'Consumer Loan': 'loan',\n",
        "    'Money transfers': 'money_transfer'\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9935336a",
      "metadata": {
        "id": "9935336a"
      },
      "outputs": [],
      "source": [
        "# Define function for saving a file\n",
        "def save_file(name, obj):\n",
        "    \"\"\"\n",
        "    Function to save an object as pickle file\n",
        "    \"\"\"\n",
        "    with open(name, 'wb') as f:\n",
        "        pickle.dump(obj, f)\n",
        "\n",
        "# Define function for loading a file\n",
        "def load_file(name):\n",
        "    \"\"\"\n",
        "    Function to load a pickle object\n",
        "    \"\"\"\n",
        "    return pickle.load(open(name, \"rb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cde95503",
      "metadata": {
        "id": "cde95503"
      },
      "source": [
        "## Process glove embeddings\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "531f3f24",
      "metadata": {
        "id": "531f3f24"
      },
      "outputs": [],
      "source": [
        "# Open the glove embeddings file and read\n",
        "with open(glove_vector_path, \"rt\") as f:\n",
        "    emb = f.readlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03d4e03a",
      "metadata": {
        "id": "03d4e03a"
      },
      "source": [
        "### 400000 unique words are there in the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b60b0e62",
      "metadata": {
        "id": "b60b0e62"
      },
      "outputs": [],
      "source": [
        "# length of embeddings\n",
        "len(emb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fb6e904",
      "metadata": {
        "id": "7fb6e904"
      },
      "source": [
        "### Check the first record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e27f3bfd",
      "metadata": {
        "id": "e27f3bfd"
      },
      "outputs": [],
      "source": [
        "# Check first record\n",
        "emb[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d5698d0",
      "metadata": {
        "id": "3d5698d0"
      },
      "outputs": [],
      "source": [
        "# Split the first record and check for vocabulary\n",
        "emb[0].split()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c86e32",
      "metadata": {
        "id": "89c86e32"
      },
      "outputs": [],
      "source": [
        "# Split the first record and check for embeddings\n",
        "emb[0].split()[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84fdfd89",
      "metadata": {
        "id": "84fdfd89"
      },
      "source": [
        "### Separate embeddings and vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "242f889d",
      "metadata": {
        "id": "242f889d"
      },
      "outputs": [],
      "source": [
        "# Initialize empty lists for vocabulary and embeddings\n",
        "vocabulary, embeddings = [], []\n",
        "\n",
        "# Process each item in the 'emb' list\n",
        "for item in emb:\n",
        "    # Split the item into a word/token and its embedding vector\n",
        "    parts = item.split()\n",
        "    word = parts[0]  # The first part is the word/token\n",
        "    embedding = parts[1:]  # The rest is the embedding vector\n",
        "\n",
        "    # Append the word/token to the 'vocabulary' list\n",
        "    vocabulary.append(word)\n",
        "\n",
        "    # Append the embedding vector to the 'embeddings' list\n",
        "    embeddings.append(embedding)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbcb6c39",
      "metadata": {
        "id": "bbcb6c39"
      },
      "source": [
        "### Convert embeddings to numpy float array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bfab44e",
      "metadata": {
        "id": "8bfab44e"
      },
      "outputs": [],
      "source": [
        "embeddings = np.array(embeddings, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01efb524",
      "metadata": {
        "id": "01efb524"
      },
      "outputs": [],
      "source": [
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99dbd776",
      "metadata": {
        "id": "99dbd776"
      },
      "source": [
        "### Add embeddings for padding and unknown items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85da0e52",
      "metadata": {
        "id": "85da0e52"
      },
      "outputs": [],
      "source": [
        "vocabulary[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fbb2c52",
      "metadata": {
        "id": "0fbb2c52"
      },
      "outputs": [],
      "source": [
        "# Initialize the vocabulary list with special tokens \"<pad>\" and \"<unk>\"\n",
        "vocabulary = [\"<pad>\", \"<unk>\"] + vocabulary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "428314b9",
      "metadata": {
        "id": "428314b9"
      },
      "outputs": [],
      "source": [
        "# Create a 50-dimensional vector filled with ones\n",
        "ones_vector = np.ones(50, dtype=np.float32)\n",
        "\n",
        "# Calculate the mean of all embeddings in the 'embeddings' list\n",
        "mean_embedding = np.mean(embeddings, axis=0)\n",
        "\n",
        "# Vertically stack the ones vector, mean embedding, and the original embeddings\n",
        "embeddings = np.vstack([ones_vector, mean_embedding, embeddings])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cac06f0",
      "metadata": {
        "id": "5cac06f0"
      },
      "outputs": [],
      "source": [
        "print(len(vocabulary), embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42b3b07a",
      "metadata": {
        "id": "42b3b07a"
      },
      "source": [
        "### Save embeddings and vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b173a0ea",
      "metadata": {
        "id": "b173a0ea"
      },
      "outputs": [],
      "source": [
        "save_file(embeddings_path, embeddings)\n",
        "save_file(vocabulary_path, vocabulary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea80e7ea",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f58d0479",
      "metadata": {
        "id": "f58d0479"
      },
      "source": [
        "## Process text data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f567f06f",
      "metadata": {
        "id": "f567f06f"
      },
      "source": [
        "### Read the data file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c71c7dfc",
      "metadata": {
        "id": "c71c7dfc"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86dffa9a",
      "metadata": {
        "id": "86dffa9a"
      },
      "source": [
        "### Drop rows where the text column is empty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "216c4a4d",
      "metadata": {
        "id": "216c4a4d"
      },
      "outputs": [],
      "source": [
        "data.dropna(subset=[text_col_name], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a70b83e2",
      "metadata": {
        "id": "a70b83e2"
      },
      "source": [
        "### Replace duplicate labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64801543",
      "metadata": {
        "id": "64801543"
      },
      "outputs": [],
      "source": [
        "# Replace values in the 'label_col' column of the 'data' DataFrame\n",
        "data.replace({label_col: product_map}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b1714dc",
      "metadata": {
        "id": "6b1714dc"
      },
      "source": [
        "### Encode the label column and save the encoder and encoded labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "900db623",
      "metadata": {
        "id": "900db623"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize a LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the LabelEncoder to the labels in the 'label_col' column of the 'data' DataFrame\n",
        "label_encoder.fit(data[label_col])\n",
        "\n",
        "# Transform the labels in the 'label_col' column to their encoded integer values\n",
        "labels = label_encoder.transform(data[label_col])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd80694",
      "metadata": {
        "id": "edd80694"
      },
      "outputs": [],
      "source": [
        "labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c367c8",
      "metadata": {
        "id": "52c367c8"
      },
      "outputs": [],
      "source": [
        "label_encoder.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7ccce6f",
      "metadata": {
        "id": "f7ccce6f"
      },
      "outputs": [],
      "source": [
        "data[label_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0544906f",
      "metadata": {
        "id": "0544906f"
      },
      "outputs": [],
      "source": [
        "save_file(labels_path, labels)\n",
        "save_file(label_encoder_path, label_encoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc16fc63",
      "metadata": {
        "id": "fc16fc63"
      },
      "source": [
        "### Process the text column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06b2e29d",
      "metadata": {
        "id": "06b2e29d"
      },
      "outputs": [],
      "source": [
        "# Extract the values from the 'text_col_name' column of the 'data' DataFrame\n",
        "input_text = data[text_col_name]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2fd241b",
      "metadata": {
        "id": "e2fd241b"
      },
      "source": [
        "### Convert text to lower case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "857dec2b",
      "metadata": {
        "id": "857dec2b"
      },
      "outputs": [],
      "source": [
        "# Convert each text item in 'input_text' to lowercase and display a progress bar\n",
        "input_text = [i.lower() for i in tqdm(input_text)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54188fc7",
      "metadata": {
        "id": "54188fc7"
      },
      "source": [
        "### Remove punctuations except apostrophe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eee07ba3",
      "metadata": {
        "id": "eee07ba3"
      },
      "outputs": [],
      "source": [
        "# Remove non-alphanumeric characters (except for single quotes and spaces) from each text item in 'input_text' and display a progress bar\n",
        "input_text = [re.sub(r\"[^\\w\\d'\\s]+\", \" \", i) for i in tqdm(input_text)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03cce62f",
      "metadata": {
        "id": "03cce62f"
      },
      "source": [
        "### Remove digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c239f6ec",
      "metadata": {
        "id": "c239f6ec"
      },
      "outputs": [],
      "source": [
        "# Remove one or more consecutive digits from each text item in 'input_text' and display a progress bar\n",
        "input_text = [re.sub(\"\\d+\", \"\", i) for i in tqdm(input_text)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fa2608b",
      "metadata": {
        "id": "7fa2608b"
      },
      "source": [
        "### Remove more than one consecutive instance of 'x'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "264dc356",
      "metadata": {
        "id": "264dc356"
      },
      "outputs": [],
      "source": [
        "# Remove consecutive occurrences of 'x' (two or more 'x's in a row) from each text item in 'input_text' and display a progress bar\n",
        "input_text = [re.sub(r'[x]{2,}', \"\", i) for i in tqdm(input_text)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dea776b",
      "metadata": {
        "id": "6dea776b"
      },
      "source": [
        "### Replace multiple spaces with single space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cd744c4",
      "metadata": {
        "id": "1cd744c4"
      },
      "outputs": [],
      "source": [
        "# Replace multiple consecutive spaces with a single space in each text item in 'input_text' and display a progress bar\n",
        "input_text = [re.sub(' +', ' ', i) for i in tqdm(input_text)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "934505ad",
      "metadata": {
        "id": "934505ad"
      },
      "source": [
        "### Tokenize the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c315fb",
      "metadata": {
        "id": "d0c315fb"
      },
      "outputs": [],
      "source": [
        "# Tokenize each text item in 'input_text' using the word_tokenize function and display a progress bar\n",
        "tokens = [word_tokenize(t) for t in tqdm(input_text)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c312593",
      "metadata": {
        "id": "5c312593"
      },
      "source": [
        "### Take the first 20 tokens in each complaint text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7627e35b",
      "metadata": {
        "id": "7627e35b"
      },
      "outputs": [],
      "source": [
        "# Limit each token sequence in 'tokens' to a maximum length of 20 tokens, padding with '<pad>' if necessary\n",
        "tokens = [i[:20] if len(i) > 19 else ['<pad>'] * (20 - len(i)) + i for i in tqdm(tokens)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be6561df",
      "metadata": {
        "id": "be6561df"
      },
      "source": [
        "### Convert tokens to integer indices from vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "288a4e01",
      "metadata": {
        "id": "288a4e01"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def token_index(tokens, vocabulary, missing='<unk>'):\n",
        "    \"\"\"\n",
        "    Convert lists of word tokens into lists of integers representing their positions in the vocabulary.\n",
        "\n",
        "    :param tokens: List of word tokens\n",
        "    :param vocabulary: List of words in the vocabulary\n",
        "    :param missing: Token for words not present in the vocabulary\n",
        "    :return: List of integers representing the word tokens\n",
        "    \"\"\"\n",
        "    idx_token = []  # Initialize a list to store the converted token indices\n",
        "\n",
        "    for text in tqdm(tokens):  # Iterate through the list of token sequences\n",
        "        idx_text = []  # Initialize a list to store the converted indices for a single token sequence\n",
        "\n",
        "        for token in text:  # Iterate through the tokens in a sequence\n",
        "            if token in vocabulary:  # Check if the token is in the vocabulary\n",
        "                idx_text.append(vocabulary.index(token))  # Append the index of the token in the vocabulary\n",
        "            else:\n",
        "                idx_text.append(vocabulary.index(missing))  # Append the index of the missing token\n",
        "\n",
        "        idx_token.append(idx_text)  # Append the list of token indices for the current sequence to the result\n",
        "\n",
        "    return idx_token  # Return the list of lists of token indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "618f32df",
      "metadata": {
        "id": "618f32df"
      },
      "outputs": [],
      "source": [
        "tokens = token_index(tokens, vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c51657a5",
      "metadata": {
        "id": "c51657a5"
      },
      "outputs": [],
      "source": [
        "len(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7fe16b6",
      "metadata": {
        "id": "e7fe16b6"
      },
      "outputs": [],
      "source": [
        "tokens[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00b35a7e",
      "metadata": {
        "id": "00b35a7e"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a056489b",
      "metadata": {
        "id": "a056489b"
      },
      "outputs": [],
      "source": [
        "vocabulary[tokens[0][0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab9c8712",
      "metadata": {
        "id": "ab9c8712"
      },
      "source": [
        "### Save the tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab83d5fb",
      "metadata": {
        "id": "ab83d5fb"
      },
      "outputs": [],
      "source": [
        "save_file(tokens_path, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e714e77c",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d52e1c1",
      "metadata": {
        "id": "8d52e1c1"
      },
      "source": [
        "## Create PyTorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8936a733",
      "metadata": {
        "id": "8936a733"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tokens, embeddings, labels):\n",
        "        \"\"\"\n",
        "        Initialize the TextDataset.\n",
        "\n",
        "        :param tokens: List of word tokens\n",
        "        :param embeddings: Word embeddings (from GloVe)\n",
        "        :param labels: List of labels\n",
        "        \"\"\"\n",
        "        self.tokens = tokens  # List of word tokens\n",
        "        self.embeddings = embeddings  # Word embeddings (from GloVe)\n",
        "        self.labels = labels  # List of labels\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Get the total number of samples in the dataset.\n",
        "\n",
        "        :return: The number of samples\n",
        "        \"\"\"\n",
        "        return len(self.tokens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Get a sample from the dataset.\n",
        "\n",
        "        :param idx: Index of the sample\n",
        "        :return: A tuple containing label and corresponding embedding\n",
        "        \"\"\"\n",
        "        label = self.labels[idx]  # Get the label for the specified index\n",
        "        embedding = self.embeddings[self.tokens[idx], :]  # Get the embedding for the specified token\n",
        "        return label, embedding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebad93b8",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f1c8577",
      "metadata": {
        "id": "8f1c8577"
      },
      "source": [
        "## Create Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b77dedc",
      "metadata": {
        "id": "8b77dedc"
      },
      "source": [
        "### RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4953da5",
      "metadata": {
        "id": "f4953da5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class RNNNetwork(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        \"\"\"\n",
        "        Initialize the RNNNetwork model.\n",
        "\n",
        "        :param input_size: Size of input embeddings\n",
        "        :param hidden_size: Size of the hidden state\n",
        "        :param num_classes: Number of output classes\n",
        "        \"\"\"\n",
        "        super(RNNNetwork, self).__init()\n",
        "        # RNN Layer\n",
        "        self.rnn = torch.nn.RNN(input_size=input_size,\n",
        "                                hidden_size=hidden_size,\n",
        "                                batch_first=True)\n",
        "        # Linear Layer\n",
        "        self.linear = torch.nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        :param input_data: Input data (sequences of embeddings)\n",
        "        :return: Output of the model\n",
        "        \"\"\"\n",
        "        _, hidden = self.rnn(input_data)\n",
        "        output = self.linear(hidden)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90d5b27e",
      "metadata": {},
      "source": [
        "### tensor flow alternate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f542abcc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class RNNNetwork(tf.keras.Model):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        \"\"\"\n",
        "        Initialize the RNNNetwork model.\n",
        "\n",
        "        :param input_size: Size of input embeddings\n",
        "        :param hidden_size: Size of the hidden state\n",
        "        :param num_classes: Number of output classes\n",
        "        \"\"\"\n",
        "        super(RNNNetwork, self).__init__()\n",
        "        # RNN Layer\n",
        "        self.rnn = layers.SimpleRNN(units=hidden_size, \n",
        "                                    return_sequences=False, \n",
        "                                    return_state=True)\n",
        "        # Linear Layer\n",
        "        self.linear = layers.Dense(num_classes)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        :param inputs: Input data (sequences of embeddings)\n",
        "        :param training: Boolean to specify if the model is in training mode\n",
        "        :return: Output of the model\n",
        "        \"\"\"\n",
        "        _, hidden = self.rnn(inputs)\n",
        "        output = self.linear(hidden)\n",
        "        return output\n",
        "\n",
        "# Example usage\n",
        "input_size = 10\n",
        "hidden_size = 20\n",
        "num_classes = 5\n",
        "\n",
        "# Instantiate the model\n",
        "model = RNNNetwork(input_size, hidden_size, num_classes)\n",
        "\n",
        "# Build the model by providing input shape\n",
        "model.build(input_shape=(None, None, input_size))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "550fc77e",
      "metadata": {
        "id": "550fc77e"
      },
      "source": [
        "### LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1383a39",
      "metadata": {
        "id": "a1383a39"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class LSTMNetwork(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        \"\"\"\n",
        "        Initialize the LSTMNetwork model.\n",
        "\n",
        "        :param input_size: Size of input embeddings\n",
        "        :param hidden_size: Size of the hidden state\n",
        "        :param num_classes: Number of output classes\n",
        "        \"\"\"\n",
        "        super(LSTMNetwork, self).__init()\n",
        "        # LSTM Layer\n",
        "        self.rnn = torch.nn.LSTM(input_size=input_size,\n",
        "                                hidden_size=hidden_size,\n",
        "                                batch_first=True)\n",
        "        # Linear Layer\n",
        "        self.linear = torch.nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        :param input_data: Input data (sequences of embeddings)\n",
        "        :return: Output of the model\n",
        "        \"\"\"\n",
        "        _, (hidden, _) = self.rnn(input_data)\n",
        "        output = self.linear(hidden[-1])\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01b34846",
      "metadata": {},
      "source": [
        "### Tensorflow Alternatives\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41b0fcc7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class LSTMNetwork(tf.keras.Model):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        \"\"\"\n",
        "        Initialize the LSTMNetwork model.\n",
        "\n",
        "        :param input_size: Size of input embeddings\n",
        "        :param hidden_size: Size of the hidden state\n",
        "        :param num_classes: Number of output classes\n",
        "        \"\"\"\n",
        "        super(LSTMNetwork, self).__init__()\n",
        "        # LSTM Layer\n",
        "        self.lstm = layers.LSTM(units=hidden_size, \n",
        "                                return_sequences=False, \n",
        "                                return_state=False)\n",
        "        # Linear Layer\n",
        "        self.linear = layers.Dense(num_classes)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        :param inputs: Input data (sequences of embeddings)\n",
        "        :param training: Boolean to specify if the model is in training mode\n",
        "        :return: Output of the model\n",
        "        \"\"\"\n",
        "        hidden = self.lstm(inputs)\n",
        "        output = self.linear(hidden)\n",
        "        return output\n",
        "\n",
        "# Example usage\n",
        "input_size = 10\n",
        "hidden_size = 20\n",
        "num_classes = 5\n",
        "\n",
        "# Instantiate the model\n",
        "model = LSTMNetwork(input_size, hidden_size, num_classes)\n",
        "\n",
        "# Build the model by providing input shape\n",
        "model.build(input_shape=(None, None, input_size))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e76960f7",
      "metadata": {
        "id": "e76960f7"
      },
      "source": [
        "### Define train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f289dabc",
      "metadata": {
        "id": "f289dabc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(train_loader, valid_loader, model, criterion, optimizer, device,\n",
        "          num_epochs, model_path):\n",
        "    \"\"\"\n",
        "    Function to train the model\n",
        "    :param train_loader: Data loader for the training dataset\n",
        "    :param valid_loader: Data loader for the validation dataset\n",
        "    :param model: Model object\n",
        "    :param criterion: Loss function\n",
        "    :param optimizer: Optimizer\n",
        "    :param device: 'cuda' (GPU) or 'cpu' (CPU)\n",
        "    :param num_epochs: Number of training epochs\n",
        "    :param model_path: Path to save the model\n",
        "    \"\"\"\n",
        "    best_loss = 1e8  # Initialize a variable to track the best validation loss\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1} of {num_epochs}\")\n",
        "        valid_loss, train_loss = [], []\n",
        "\n",
        "        model.train()  # Set the model to training mode\n",
        "        # Training loop\n",
        "        for batch_labels, batch_data in tqdm(train_loader):\n",
        "            # Move data to GPU if available\n",
        "            batch_labels = batch_labels.to(device)\n",
        "            batch_labels = batch_labels.type(torch.LongTensor)\n",
        "            batch_data = batch_data.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            batch_output = model(batch_data)\n",
        "            batch_output = torch.squeeze(batch_output)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(batch_output, batch_labels)\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            # Backward pass and gradient update step\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        # Validation loop\n",
        "        for batch_labels, batch_data in tqdm(valid_loader):\n",
        "            # Move data to GPU if available\n",
        "            batch_labels = batch_labels.to(device)\n",
        "            batch_labels = batch_labels.type(torch.LongTensor)\n",
        "            batch_data = batch_data.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            batch_output = model(batch_data)\n",
        "            batch_output = torch.squeeze(batch_output)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(batch_output, batch_labels)\n",
        "            valid_loss.append(loss.item())\n",
        "\n",
        "        # Calculate mean losses for the epoch\n",
        "        t_loss = np.mean(train_loss)\n",
        "        v_loss = np.mean(valid_loss)\n",
        "        print(f\"Train Loss: {t_loss}, Validation Loss: {v_loss}\")\n",
        "\n",
        "        if v_loss < best_loss:\n",
        "            best_loss = v_loss\n",
        "            # Save the model if the validation loss improves\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "        print(f\"Best Validation Loss: {best_loss}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "853388ef",
      "metadata": {
        "id": "853388ef"
      },
      "source": [
        "### Define test function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b9e405f",
      "metadata": {
        "id": "6b9e405f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def test(test_loader, model, criterion, device):\n",
        "    \"\"\"\n",
        "    Function to test the model\n",
        "    :param test_loader: Data loader for the test dataset\n",
        "    :param model: Model object\n",
        "    :param criterion: Loss function\n",
        "    :param device: 'cuda' (GPU) or 'cpu' (CPU)\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = []  # Initialize a list to store test losses\n",
        "    test_accu = []  # Initialize a list to store test accuracies\n",
        "\n",
        "    for batch_labels, batch_data in tqdm(test_loader):\n",
        "        # Move data to the specified device\n",
        "        batch_labels = batch_labels.to(device)\n",
        "        batch_labels = batch_labels.type(torch.LongTensor)\n",
        "        batch_data = batch_data.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        batch_output = model(batch_data)\n",
        "        batch_output = torch.squeeze(batch_output)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(batch_output, batch_labels)\n",
        "        test_loss.append(loss.item())\n",
        "\n",
        "        # Compute batch predictions\n",
        "        batch_preds = torch.argmax(batch_output, axis=1)\n",
        "\n",
        "        # Move predictions to CPU\n",
        "        if torch.cuda.is_available():\n",
        "            batch_labels = batch_labels.cpu()\n",
        "            batch_preds = batch_preds.cpu()\n",
        "\n",
        "        # Compute accuracy and append to the list\n",
        "        test_accu.append(accuracy_score(batch_labels.detach().numpy(), batch_preds.detach().numpy()))\n",
        "\n",
        "    # Calculate the mean test loss and test accuracy\n",
        "    test_loss = np.mean(test_loss)\n",
        "    test_accu = np.mean(test_accu)\n",
        "\n",
        "    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accu}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a2260e4",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4163f818",
      "metadata": {
        "id": "4163f818"
      },
      "source": [
        "## Train RNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e752fd29",
      "metadata": {
        "id": "e752fd29"
      },
      "source": [
        "### Load the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9aaae86",
      "metadata": {
        "id": "c9aaae86"
      },
      "outputs": [],
      "source": [
        "# Load tokenized text data from a file\n",
        "tokens = load_file(tokens_path)\n",
        "\n",
        "# Load label data from a file\n",
        "labels = load_file(labels_path)\n",
        "\n",
        "# Load word embeddings from a file\n",
        "embeddings = load_file(embeddings_path)\n",
        "\n",
        "# Load a label encoder object from a file\n",
        "label_encoder = load_file(label_encoder_path)\n",
        "\n",
        "# Calculate the number of unique classes based on the label encoder\n",
        "num_classes = len(label_encoder.classes_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ad46f7e",
      "metadata": {
        "id": "2ad46f7e"
      },
      "source": [
        "### Split data into train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7916b320",
      "metadata": {
        "id": "7916b320"
      },
      "outputs": [],
      "source": [
        "# Split the data into a training set and a temporary set (20% of the data as the test set)\n",
        "X_train, X_test, y_train, y_test = train_test_split(tokens, labels, test_size=0.2)\n",
        "\n",
        "# Further split the temporary set into a training set (60% of the original data) and a validation set (20% of the original data)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "171cc1be",
      "metadata": {
        "id": "171cc1be"
      },
      "source": [
        "### Create PyTorch datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af22498f",
      "metadata": {
        "id": "af22498f"
      },
      "outputs": [],
      "source": [
        "# Create a training dataset using X_train, word embeddings, and y_train\n",
        "train_dataset = TextDataset(X_train, embeddings, y_train)\n",
        "\n",
        "# Create a validation dataset using X_valid, word embeddings, and y_valid\n",
        "valid_dataset = TextDataset(X_valid, embeddings, y_valid)\n",
        "\n",
        "# Create a test dataset using X_test, word embeddings, and y_test\n",
        "test_dataset = TextDataset(X_test, embeddings, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "030610ea",
      "metadata": {
        "id": "030610ea"
      },
      "source": [
        "### Create data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0dcc6dd",
      "metadata": {
        "id": "a0dcc6dd"
      },
      "outputs": [],
      "source": [
        "# Create a training data loader with batch size 16, shuffling the data, and dropping the last batch if it's smaller than the batch size\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
        "\n",
        "# Create a validation data loader with batch size 16\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16)\n",
        "\n",
        "# Create a test data loader with batch size 16\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af02c4c2",
      "metadata": {
        "id": "af02c4c2"
      },
      "source": [
        "### Create model object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aaacda1",
      "metadata": {
        "id": "7aaacda1"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the RNNNetwork model with the specified input size, hidden size, and number of output classes\n",
        "model = RNNNetwork(input_size, hidden_size, num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c88a3f8",
      "metadata": {
        "id": "7c88a3f8"
      },
      "source": [
        "### Move the model to GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca465cd6",
      "metadata": {
        "id": "ca465cd6"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1deebde4",
      "metadata": {
        "id": "1deebde4"
      },
      "source": [
        "### Define loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4becc10",
      "metadata": {
        "id": "d4becc10"
      },
      "outputs": [],
      "source": [
        "# Define the loss function (CrossEntropyLoss) for classification tasks\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer (Adam) for updating model parameters during training\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Determine the computing device - use GPU if available, otherwise, use CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f90ad48",
      "metadata": {
        "id": "7f90ad48"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f80daf65",
      "metadata": {
        "id": "f80daf65"
      },
      "outputs": [],
      "source": [
        "# Call the 'train' function to train the model\n",
        "train(train_loader, valid_loader, model, criterion, optimizer, device, num_epochs, rnn_model_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7db3bcb8",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1215b67c",
      "metadata": {
        "id": "1215b67c"
      },
      "source": [
        "## Train LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5e3ceb0",
      "metadata": {
        "id": "a5e3ceb0"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the LSTMNetwork model with the specified input size, hidden size, and number of output classes\n",
        "model = LSTMNetwork(input_size, hidden_size, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92a8e560",
      "metadata": {
        "id": "92a8e560"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7aee94f",
      "metadata": {
        "id": "d7aee94f"
      },
      "outputs": [],
      "source": [
        "# Define the loss function (CrossEntropyLoss) for classification tasks\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer (Adam) for updating model parameters during training\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Determine the computing device - use GPU if available, otherwise, use CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f9d0c17",
      "metadata": {
        "id": "9f9d0c17"
      },
      "outputs": [],
      "source": [
        "# Call the 'train' function to train the LSTM model\n",
        "train(train_loader, valid_loader, model, criterion, optimizer, device, num_epochs, lstm_model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1882978",
      "metadata": {
        "id": "f1882978"
      },
      "outputs": [],
      "source": [
        "test(test_loader, model, criterion, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a74eb71",
      "metadata": {
        "id": "8a74eb71"
      },
      "source": [
        "## Predict on new text\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff13ab78",
      "metadata": {
        "id": "ff13ab78"
      },
      "outputs": [],
      "source": [
        "input_text = '''I am a victim of Identity Theft & currently have an Experian account that \n",
        "I can view my Experian Credit Report and getting notified when there is activity on \n",
        "my Experian Credit Report. For the past 3 days I've spent a total of approximately 9 \n",
        "hours on the phone with Experian. Every time I call I get transferred repeatedly and \n",
        "then my last transfer and automated message states to press 1 and leave a message and \n",
        "someone would call me. Every time I press 1 I get an automatic message stating than you \n",
        "before I even leave a message and get disconnected. I call Experian again, explain what \n",
        "is happening and the process begins again with the same end result. I was trying to have \n",
        "this issue attended and resolved informally but I give up after 9 hours. There are hard \n",
        "hit inquiries on my Experian Credit Report that are fraud, I didn't authorize, or recall \n",
        "and I respectfully request that Experian remove the hard hit inquiries immediately just \n",
        "like they've done in the past when I was able to speak to a live Experian representative \n",
        "in the United States. The following are the hard hit inquiries : BK OF XXXX XX/XX/XXXX \n",
        "XXXX XXXX XXXX  XX/XX/XXXX XXXX  XXXX XXXX  XX/XX/XXXX XXXX  XX/XX/XXXX XXXX  XXXX \n",
        "XX/XX/XXXX'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "678d4e28",
      "metadata": {
        "id": "678d4e28"
      },
      "source": [
        "### Process input text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dded0d3",
      "metadata": {
        "id": "1dded0d3"
      },
      "outputs": [],
      "source": [
        "# Convert the input text to lowercase\n",
        "input_text = input_text.lower()\n",
        "\n",
        "# Replace non-alphanumeric characters (except for ' and spaces) with a space\n",
        "input_text = re.sub(r\"[^\\w\\d'\\s]+\", \" \", input_text)\n",
        "\n",
        "# Remove all digits from the text\n",
        "input_text = re.sub(\"\\d+\", \"\", input_text)\n",
        "\n",
        "# Remove consecutive occurrences of 'x' with two or more repetitions\n",
        "input_text = re.sub(r'[x]{2,}', \"\", input_text)\n",
        "\n",
        "# Replace consecutive spaces with a single space\n",
        "input_text = re.sub(' +', ' ', input_text)\n",
        "\n",
        "# Tokenize the preprocessed text into a list of words\n",
        "tokens = word_tokenize(input_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d09d91b1",
      "metadata": {
        "id": "d09d91b1"
      },
      "source": [
        "### Add padding if the length of tokens is less than 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ba95fe0",
      "metadata": {
        "id": "7ba95fe0"
      },
      "outputs": [],
      "source": [
        "# Pad the list of tokens to a fixed length of 20 by adding '<pad>' tokens to the beginning\n",
        "tokens = ['<pad>'] * (20 - len(tokens)) + tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82fbbab5",
      "metadata": {
        "id": "82fbbab5"
      },
      "source": [
        "### Tokenize the input text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "821fb5de",
      "metadata": {
        "id": "821fb5de"
      },
      "outputs": [],
      "source": [
        "idx_token = []  # Initialize a list to store the token indices\n",
        "for token in tokens:\n",
        "    if token in vocabulary:\n",
        "        # If the token is in the vocabulary, get its index in the vocabulary\n",
        "        idx_token.append(vocabulary.index(token))\n",
        "    else:\n",
        "        # If the token is not in the vocabulary, use the index of the '<unk>' token\n",
        "        idx_token.append(vocabulary.index('<unk>'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "540cb058",
      "metadata": {
        "id": "540cb058"
      },
      "source": [
        "### Get embeddings for tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d6cc01c",
      "metadata": {
        "id": "1d6cc01c"
      },
      "outputs": [],
      "source": [
        "# Extract word embeddings from the 'embeddings' array for the tokens in 'idx_token'\n",
        "token_emb = embeddings[idx_token, :]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de584626",
      "metadata": {
        "id": "de584626"
      },
      "source": [
        "### Convert to torch tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "780d42e4",
      "metadata": {
        "id": "780d42e4"
      },
      "outputs": [],
      "source": [
        "# Convert the 'token_emb' NumPy array into a PyTorch tensor\n",
        "inp = torch.from_numpy(token_emb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e91e281c",
      "metadata": {
        "id": "e91e281c"
      },
      "source": [
        "### Move the tensor to GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f15e636d",
      "metadata": {
        "id": "f15e636d"
      },
      "outputs": [],
      "source": [
        "inp = inp.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebed4640",
      "metadata": {
        "id": "ebed4640"
      },
      "source": [
        "### Create a batch of one record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c3865b5",
      "metadata": {
        "id": "5c3865b5"
      },
      "outputs": [],
      "source": [
        "# Add a new dimension to the 'inp' tensor\n",
        "inp = torch.unsqueeze(inp, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2cc919d",
      "metadata": {
        "id": "e2cc919d"
      },
      "source": [
        "### Load label encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92a17e27",
      "metadata": {
        "id": "92a17e27"
      },
      "outputs": [],
      "source": [
        "# Load a label encoder from a file\n",
        "label_encoder = load_file(label_encoder_path)\n",
        "\n",
        "# Determine the number of unique classes based on the loaded label encoder\n",
        "num_classes = len(label_encoder.classes_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07dd7955",
      "metadata": {
        "id": "07dd7955"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdbe841b",
      "metadata": {
        "id": "cdbe841b"
      },
      "source": [
        "### RNN prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a23eb5c",
      "metadata": {
        "id": "1a23eb5c"
      },
      "outputs": [],
      "source": [
        "# Create a model object (RNNNetwork) with the specified input size, hidden size, and number of classes\n",
        "model = RNNNetwork(input_size, hidden_size, num_classes)\n",
        "\n",
        "# Load the trained model weights from the specified path\n",
        "model.load_state_dict(torch.load(rnn_model_path))\n",
        "\n",
        "# Move the model to the GPU if a GPU is available (optional)\n",
        "if torch.cuda.is available():\n",
        "    model = model.cuda()\n",
        "\n",
        "# Perform a forward pass with the input tensor (inp)\n",
        "out = torch.squeeze(model(inp))\n",
        "\n",
        "# Find the predicted class by taking the class with the highest score\n",
        "# and mapping it back to the original class label using the label encoder\n",
        "predicted_class_index = torch.argmax(out)\n",
        "prediction = label_encoder.classes_[predicted_class_index]\n",
        "\n",
        "# Print the predicted class\n",
        "print(f\"Predicted Class: {prediction}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1426d72f",
      "metadata": {
        "id": "1426d72f"
      },
      "source": [
        "### LSTM prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db3cce1e",
      "metadata": {
        "id": "db3cce1e"
      },
      "outputs": [],
      "source": [
        "# Create a model object (LSTMNetwork) with the specified input size, hidden size, and number of classes\n",
        "model = LSTMNetwork(input_size, hidden_size, num_classes)\n",
        "\n",
        "# Load the trained model weights from the specified path\n",
        "model.load_state_dict(torch.load(lstm_model_path))\n",
        "\n",
        "# Move the model to the GPU if a GPU is available (optional)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "# Perform a forward pass with the input tensor (inp)\n",
        "out = torch.squeeze(model(inp))\n",
        "\n",
        "# Find the predicted class by taking the class with the highest score\n",
        "# and mapping it back to the original class label using the label encoder\n",
        "predicted_class_index = torch.argmax(out)\n",
        "prediction = label_encoder.classes_[predicted_class_index]\n",
        "\n",
        "# Print the predicted class\n",
        "print(f\"Predicted Class: {prediction}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb8a232c",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "290e2616",
      "metadata": {
        "id": "290e2616"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "99dbd776",
        "42b3b07a",
        "f567f06f",
        "86dffa9a",
        "a70b83e2",
        "6b1714dc",
        "fc16fc63",
        "e2fd241b",
        "54188fc7",
        "03cce62f",
        "7fa2608b",
        "6dea776b",
        "934505ad",
        "5c312593",
        "be6561df",
        "ab9c8712",
        "8b77dedc",
        "550fc77e",
        "e752fd29",
        "2ad46f7e",
        "171cc1be",
        "030610ea",
        "af02c4c2",
        "7c88a3f8",
        "1deebde4",
        "7f90ad48",
        "678d4e28",
        "d09d91b1",
        "82fbbab5",
        "540cb058",
        "de584626",
        "e91e281c",
        "ebed4640",
        "e2cc919d",
        "cdbe841b",
        "1426d72f"
      ],
      "name": "RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
